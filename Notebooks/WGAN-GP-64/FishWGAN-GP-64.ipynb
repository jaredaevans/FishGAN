{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bVmCpG7EURhZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np  \n",
    "import pandas as pd \n",
    "\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import glob\n",
    "import imageio\n",
    "\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import shutil\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from scipy import linalg\n",
    "\n",
    "import xml.etree.ElementTree as ET \n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "from IPython import display\n",
    "from IPython.display import Image as IpyImage\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import UpSampling2D\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Add\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.metrics import Accuracy\n",
    "\n",
    "from tensorflow.keras.models import save_model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "VBhXJBBrozFD",
    "outputId": "3ee80c8f-e0de-41a6-fa49-bf4f8659dc3c"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "    print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "    print('and then re-execute this cell.')\n",
    "else:\n",
    "    print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "VFvgBtDEU60N",
    "outputId": "27791839-264d-4242-c6d6-232db657013d"
   },
   "outputs": [],
   "source": [
    "try: # detect TPUs\n",
    "    # detect and init the TPU\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "\n",
    "    # instantiate a distribution strategy\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "except ValueError: # detect GPUs\n",
    "    #strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n",
    "    strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
    "    #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n",
    "\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)\n",
    "\n",
    "FishDIR='../../../CustomFish/'\n",
    "GenFishDIR='./'\n",
    "GIFDIR = './GIFs/'\n",
    "#h5DIR = '/content/drive/My Drive/h5s/'\n",
    "#h5inDIR = '/content/drive/My Drive/h5s/'\n",
    "h5inDIR = './'\n",
    "h5DIR = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "03VaFNSKU8t4"
   },
   "outputs": [],
   "source": [
    "codings_size = 256\n",
    "dropoutVal = 0.4\n",
    "LReluAlpha = 0.2\n",
    "\n",
    "##############\n",
    "### Layers ###\n",
    "##############\n",
    "\n",
    "# from 1710.10196 use mini batch standard dev on discriminator output (only needs to be done once)\n",
    "# need to combine layers to fade out, inherit Add class\n",
    "# fade parameter is updated in WGANGP class\n",
    "class AddWithFade(Add):\n",
    "    def __init__(self, fade=0.0, **kwargs):\n",
    "        super(AddWithFade, self).__init__(**kwargs)\n",
    "        # fade will increase linearly from 0-1 \n",
    "        self.fade = K.variable(fade, name='fade_param')\n",
    " \n",
    "    def _merge_function(self, inputs):\n",
    "        assert (len(inputs) == 2)\n",
    "        #input[0] = lower res layer, input[1] = higher res layer \n",
    "        output = ((1. - self.fade) * inputs[0]) + (self.fade * inputs[1])\n",
    "        return output\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super(AddWithFade, self).get_config()\n",
    "        base_config[\"fade\"] = self.fade\n",
    "        return base_config\n",
    "\n",
    "# update the fade parameter in the model\n",
    "def update_fade(model,newfade):\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, AddWithFade):\n",
    "            K.set_value(layer.fade,newfade)\n",
    "    \n",
    "# toggle trainability of WGAN\n",
    "def toggle_train(WGAN, trainTog=True, size=codings_size):\n",
    "    if trainTog == False:\n",
    "        WGAN.trainFreeze = True\n",
    "        for layer in WGAN.discriminator.layers:\n",
    "            if layer.output.shape[1] != size:\n",
    "                layer.trainable = False\n",
    "        for layer in WGAN.generator.layers:\n",
    "            if layer.output.shape[1] != size:\n",
    "                layer.trainable = False\n",
    "    else:\n",
    "        WGAN.trainFreeze = False\n",
    "        for layer in WGAN.discriminator.layers:\n",
    "            layer.trainable = True\n",
    "        for layer in WGAN.generator.layers:\n",
    "            layer.trainable = True     \n",
    "            \n",
    "# this has the generator creating realistic deviations across batches\n",
    "# useful discussion: https://towardsdatascience.com/gan-ways-to-improve-gan-performance-acf37f9f59b\n",
    "# \"We append the similarity o(x) in one of the dense layers in the discriminator\n",
    "#  to classify whether this image is real or generated. If the mode starts to collapse, \n",
    "#  the similarity of generated images increases. The discriminator can use this score \n",
    "#  to detect generated images and penalize the generator if mode is collapsing.\"\n",
    "class MBStDev(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.smallParam = 1e-8 \n",
    "        super(MBStDev, self).__init__(**kwargs)\n",
    " \n",
    "    # perform the operation\n",
    "    def call(self, ins):\n",
    "        # mean value for each pixel across channels\n",
    "        pixMean = K.mean(ins, axis=0, keepdims=True)\n",
    "        # standard deviation across each pixel coord (small param regulates singularity)\n",
    "        stDev = K.sqrt(K.mean(K.square(ins - pixMean), axis=0, keepdims=True)+self.smallParam)\n",
    "        # mean standard deviation across each pixel coord\n",
    "        meanStDev = K.mean(stDev, keepdims=True)\n",
    "        # scale this up to be the size of one input feature map for each sample\n",
    "        shape = K.shape(ins)\n",
    "        outs = K.tile(meanStDev, (shape[0], shape[1], shape[2], 1))\n",
    "        # concatenate with the output\n",
    "        joinedInandOut = K.concatenate([ins, outs], axis=-1)\n",
    "        return joinedInandOut\n",
    " \n",
    "    # corrects the output shape to match the joint values\n",
    "    def correct_output_shape(self, input_shape):\n",
    "        # create a copy of the input shape as a list\n",
    "        input_shape = list(input_shape)\n",
    "        # add one to the channel dimension (assume channels-last)\n",
    "        input_shape[-1] += 1\n",
    "        # convert list to a tuple\n",
    "        return tuple(input_shape)\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super(MBStDev, self).get_config()\n",
    "        return base_config\n",
    "\n",
    "# from 1710.10196 - use pixel normalization, a variant of \"local response normalization\"\n",
    "# Used to \"disallow the scenario where the magnitudes in the generator and discriminator spiral out \n",
    "# of control as a result of competition\" - apply BEFORE activation function in generator only\n",
    "class PixelNorm(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.smallParam = 1e-8 \n",
    "        super(PixelNorm, self).__init__(**kwargs)\n",
    "    \n",
    "    def call(self, ins):\n",
    "        # -1 is over the filters\n",
    "        sqPixMean = K.mean(ins**2 + self.smallParam, axis=-1, keepdims=True)\n",
    "        return ins / K.sqrt(sqPixMean)\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super(PixelNorm, self).get_config()\n",
    "        return base_config\n",
    "\n",
    "# this kernel implements equalized learning rate\n",
    "# adapted from https://github.com/keras-team/keras/blob/master/keras/layers/convolutional.py\n",
    "class Conv2DELR(Conv2D):\n",
    "    def __init__(self, *args, cHe=None, kernel_initializer=tf.keras.initializers.RandomNormal(stddev=1.), **kwargs):\n",
    "        #if kernel_initializer != tf.keras.initializers.RandomNormal(stddev=1.):\n",
    "        #    print(\"Warning:  overriding default kernel_initializer in Conv2DELR with {}\".format(str(kernel_initializer)))\n",
    "        if cHe is not None:\n",
    "            self.c = cHe\n",
    "        super().__init__(*args, kernel_initializer=kernel_initializer, **kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super().build(input_shape)\n",
    "        # The number of inputs\n",
    "        n = np.product([int(val) for val in input_shape[1:]])\n",
    "        # He initialisation constant\n",
    "        self.c = np.sqrt(2/n)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self.rank == 2:\n",
    "            outputs = K.conv2d(\n",
    "                inputs,\n",
    "                self.kernel*self.c, # scale kernel\n",
    "                strides=self.strides,\n",
    "                padding=self.padding,\n",
    "                data_format=self.data_format,\n",
    "                dilation_rate=self.dilation_rate)\n",
    "\n",
    "        if self.use_bias:\n",
    "            outputs = K.bias_add(\n",
    "                outputs,\n",
    "                self.bias,\n",
    "                data_format=self.data_format)\n",
    "\n",
    "        if self.activation is not None:\n",
    "            return self.activation(outputs)\n",
    "        return outputs\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super(Conv2D, self).get_config()\n",
    "        base_config['cHe'] = self.c\n",
    "        return base_config\n",
    "\n",
    "#############\n",
    "### Model ###\n",
    "#############\n",
    "\n",
    "# from https://keras.io/examples/generative/wgan_gp/\n",
    "# Define the loss functions to be used for discrimiator\n",
    "# This should be (fake_loss - real_loss)\n",
    "# We will add the gradient penalty later to this loss function\n",
    "def critic_loss(real_img, fake_img):\n",
    "    real_loss = tf.reduce_mean(real_img)\n",
    "    fake_loss = tf.reduce_mean(fake_img)\n",
    "    # \n",
    "    # this is a simple implementation of the drift loss\n",
    "    epsilonDrift = 0.001\n",
    "    epsilonLoss = epsilonDrift * tf.reduce_mean(tf.nn.l2_loss(real_img))\n",
    "    return fake_loss - real_loss + epsilonLoss\n",
    "\n",
    "# Define the loss functions to be used for generator\n",
    "def generator_loss(fake_img):\n",
    "    return -tf.reduce_mean(fake_img)\n",
    "\n",
    "\n",
    "\n",
    "## learning rate modifcations\n",
    "def set_lr(opt, lr):\n",
    "    opt.lr = lr\n",
    "\n",
    "def adapt_lr_GAN(optg, optd, histg, histd, lrmax=0.001, lrmin=0.00001):\n",
    "    pauseFade = False\n",
    "    if len(hist1) > 20: \n",
    "        rhg = histg[-20:]\n",
    "        rhd = histd[-20:]\n",
    "        hdiff = rhg - rhd\n",
    "        avg = np.mean(rhg)\n",
    "        avd = np.mean(rhd)\n",
    "        avdiff = np.mean(hdiff)\n",
    "        changeg = np.mean(rhg[-10:])-np.mean(rhg[:10])\n",
    "        changed = np.mean(rhd[-10:])-np.mean(rhd[:10])\n",
    "        changediff = np.mean(hdiff[-10:])-np.mean(hdiff[:10])\n",
    "        stdg = np.std(rhg)\n",
    "        stdd = np.std(rhd)\n",
    "        stddiff = np.std(hdiff)\n",
    "        if 3*stdg > stddiff:\n",
    "            optg.lr = max(optg.lr/2,lrmin)\n",
    "            optd.lr = max(optd.lr/2,lrmin)\n",
    "            print(\"Cond 1 adapt: \".format(optg.lr))\n",
    "        elif changeg > 5 and avg > 30:\n",
    "            optg.lr = min(2*optg.lr,lrmax)\n",
    "            optg.lr = min(2*optg.lr,lrmax)\n",
    "            print(\"Cond 2 adapt: \".format(optg.lr))\n",
    "            pauseFade = True\n",
    "        elif stdg > changeg and avd < 0:\n",
    "            optg.lr = max(optg.lr/2,lrmin)\n",
    "            optd.lr = max(optd.lr/2,lrmin)\n",
    "        print(\"Cond 3 adapt: \".format(optg.lr))\n",
    "        print(\"avg {}; delg {}; stdg {}\".format(avg,changeg, stdg))\n",
    "        print(\"avd {}; deld {}; stdd {}\".format(avg,changeg, stdg))\n",
    "        print(\"avdiff {}; deldiff {}; stddiff {}\".format(avg,changeg, stdg))\n",
    "    return pauseFade\n",
    "\n",
    "def adjust_lr(opt,lrmax=0.00006,lrmin=0.00002):\n",
    "    # randomly assign a learning rate to both the discriminator and generator each iteration\n",
    "    newlr = 1./(1./lrmax + tf.random.uniform(shape=(),maxval=1./lrmin))\n",
    "    opt.lr = newlr\n",
    "\n",
    "def adjust_lr_prob(opt,lrhigh=0.005,prob=0.003,lrmax=0.001,lrmin=0.0001):#,lrmax=0.001,lrmin=0.0001):\n",
    "    # randomly assign a learning rate to both the discriminator and generator each iteration\n",
    "    if tf.random.uniform(shape=(),maxval=1.) < prob:\n",
    "        opt.lr = lrhigh\n",
    "    else:\n",
    "        adjust_lr(opt,lrmax=lrmax,lrmin=lrmin)\n",
    "\n",
    "# implementation of wasserstein loss with gradient penalty\n",
    "# Useful information: https://medium.com/@jonathan_hui/gan-wasserstein-gan-wgan-gp-6a1a2aa1b490\n",
    "# keras implementation: https://keras.io/examples/generative/wgan_gp/\n",
    "class WGANGP(keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        discriminator,\n",
    "        generator,\n",
    "        latent_dim,\n",
    "        discriminator_steps=1,\n",
    "        gp_weight=10.0,\n",
    "        #nMaxFade = 800000 this is the recommended value for faces\n",
    "        nMaxFade = 100000\n",
    "    ):\n",
    "        super(WGANGP, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.d_steps = discriminator_steps\n",
    "        self.gp_weight = gp_weight\n",
    "        self.nMaxFade = nMaxFade\n",
    "        self.fade = 0.0\n",
    "        self.nRunFade = 0\n",
    "        self.trainFreeze = False\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, d_loss_fn, g_loss_fn):\n",
    "        super(WGANGP, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_loss_fn = d_loss_fn\n",
    "        self.g_loss_fn = g_loss_fn\n",
    "        \n",
    "    def get_config(self):\n",
    "        base_config = super(keras.Model,self).get_config()\n",
    "        base_config[\"discriminator\"] = self.discriminator\n",
    "        base_config[\"d_optimizer\"] = self.d_optimizer\n",
    "        base_config[\"d_loss_fn\"] = self.d_loss_fn\n",
    "        base_config[\"generator\"] = self.generator\n",
    "        base_config[\"g_loss_fn\"] = self.g_loss_fn\n",
    "        base_config[\"g_optimizer\"] = self.g_optimizer\n",
    "        base_config[\"latent_dim\"] = self.latent_dim\n",
    "        base_config[\"discriminator_steps\"] = self.d_steps\n",
    "        base_config[\"gp_weight\"] = self.gp_weight\n",
    "        base_config[\"nMaxFade\"] = self.nMaxFade\n",
    "        return base_config\n",
    "\n",
    "    def gradient_penalty(self, batch_size, real_images, fake_images):\n",
    "        \"\"\" Calculates the gradient penalty.\n",
    "\n",
    "        This loss is calculated on an interpolated image\n",
    "        and added to the discriminator loss.\n",
    "        \"\"\"\n",
    "        # get the interplated image\n",
    "        alpha = tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0)\n",
    "        diff = fake_images - real_images\n",
    "        interpolated = real_images + alpha * diff\n",
    "\n",
    "        with tf.GradientTape() as gp_tape:\n",
    "            gp_tape.watch(interpolated)\n",
    "            # 1. Get the discriminator output for this interpolated image.\n",
    "            pred = self.discriminator(interpolated, training=True)\n",
    "\n",
    "        # 2. Calculate the gradients w.r.t to this interpolated image.\n",
    "        grads = gp_tape.gradient(pred, [interpolated])[0]\n",
    "        # 3. Calcuate the norm of the gradients\n",
    "        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
    "        gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "        return gp\n",
    "\n",
    "    def train_step(self, real_images, withFade = True, adaptlr = False, randg=False, randd=False):\n",
    "        if isinstance(real_images, tuple):\n",
    "            real_images = real_images[0]\n",
    "\n",
    "        # Get the batch size\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        \n",
    "        #print(\"Batch Size {}\".format(batch_size))\n",
    "        \n",
    "        # update the fade is model is being run with fade\n",
    "        if self.fade < 1:\n",
    "            if withFade and not self.trainFreeze:\n",
    "                self.nRunFade += batch_size\n",
    "                self.fade = min(self.nRunFade,self.nMaxFade)/self.nMaxFade\n",
    "                update_fade(self.generator,self.fade)\n",
    "                update_fade(self.discriminator,self.fade)\n",
    "\n",
    "        # For each batch, we are going to perform the\n",
    "        # following steps as laid out in the original paper.\n",
    "        # 1. Train the generator and get the generator loss\n",
    "        # 2. Train the discriminator and get the discriminator loss\n",
    "        # 3. Calculate the gradient penalty\n",
    "        # 4. Multiply this gradient penalty with a constant weight factor\n",
    "        # 5. Add gradient penalty to the discriminator loss\n",
    "        # 6. Return generator and discriminator losses as a loss dictionary.\n",
    "\n",
    "        # Train discriminator first. The original paper recommends training\n",
    "        # the discriminator for `x` more steps (typically 5) as compared to\n",
    "        # one step of the generator. Here we will train it for 3 extra steps\n",
    "        # as compared to 5 to reduce the training time.\n",
    "        for i in range(self.d_steps):\n",
    "            # Get the latent vector\n",
    "            random_latent_vectors = tf.random.normal(\n",
    "                shape=(batch_size, self.latent_dim)\n",
    "            )\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Generate fake images from the latent vector\n",
    "                fake_images = self.generator(random_latent_vectors, training=True)\n",
    "                # Get the logits for the fake images\n",
    "                fake_logits = self.discriminator(fake_images, training=True)\n",
    "                # Get the logits for real images\n",
    "                real_logits = self.discriminator(real_images, training=True)\n",
    "\n",
    "                # Calculate discriminator loss using fake and real logits\n",
    "                d_cost = self.d_loss_fn(real_img=real_logits, fake_img=fake_logits)\n",
    "                # Calculate the gradient penalty\n",
    "                gp = self.gradient_penalty(batch_size, real_images, fake_images)\n",
    "                # Add the gradient penalty to the original discriminator loss\n",
    "                d_loss = d_cost + gp * self.gp_weight\n",
    "\n",
    "            if randd:\n",
    "                adjust_lr(self.d_optimizer)\n",
    "            # Get the gradients w.r.t the discriminator loss\n",
    "            d_gradient = tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "            # Update the weights of the discriminator using the discriminator optimizer\n",
    "            \n",
    "            self.d_optimizer.apply_gradients(\n",
    "                zip(d_gradient, self.discriminator.trainable_variables)\n",
    "            )\n",
    "\n",
    "        # Train the generator now.\n",
    "        # Get the latent vector\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Generate fake images using the generator\n",
    "            generated_images = self.generator(random_latent_vectors, training=True)\n",
    "            # Get the discriminator logits for fake images\n",
    "            gen_img_logits = self.discriminator(generated_images, training=True)\n",
    "            # Calculate the generator loss\n",
    "            g_loss = self.g_loss_fn(gen_img_logits)\n",
    "\n",
    "        if randg:\n",
    "            adjust_lr(self.g_optimizer)\n",
    "        # Get the gradients w.r.t the generator loss\n",
    "        gen_gradient = tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        # Update the weights of the generator using the generator optimizer\n",
    "        \n",
    "        self.g_optimizer.apply_gradients(\n",
    "            zip(gen_gradient, self.generator.trainable_variables)\n",
    "        )\n",
    "        return {\"d_loss\": d_loss, \"g_loss\": g_loss}\n",
    "\n",
    "# take from a model that criticises an nxnx3 figure to one that criticizes a 2nx2nx3 figure\n",
    "def add_critic_level(old_c_model, new_level=8, nSkip=3,nSkipPassby=1,nColors=3,nameX=None):\n",
    "    namebase = nameX\n",
    "    if nameX == None:\n",
    "        namebase = str(new_level)\n",
    "        \n",
    "    thisleveldict = leveldict[new_level]\n",
    "    filters = thisleveldict['filters']\n",
    "    conv2filters = leveldict[new_level/2]['filters']\n",
    "    \n",
    "    #define new input layer\n",
    "    layer_in = Input(shape=(new_level, new_level, nColors,),name=\"Input_C0_{}\".format(namebase)) \n",
    "    \n",
    "    # new round start passby here\n",
    "    conv_0 = Conv2DELR(filters, (1,1), padding=\"SAME\",name=\"Conv_C0_{}\".format(namebase))(layer_in)\n",
    "    act_0 = LeakyReLU(alpha=0.2,name=\"Act_C0_{}\".format(namebase))(conv_0)\n",
    "    # first layer set (newround start main model here)\n",
    "    conv_1 = Conv2DELR(filters, (3,3), padding=\"SAME\",name=\"Conv_C1_{}\".format(namebase))(act_0)\n",
    "    act_1 = LeakyReLU(alpha=0.2,name=\"Act_C1_{}\".format(namebase))(conv_1)\n",
    "    # second layer set\n",
    "    conv_2 = Conv2DELR(conv2filters, (3,3), padding=\"SAME\",name=\"Conv_C2_{}\".format(namebase))(act_1)\n",
    "    act_2 = LeakyReLU(alpha=0.2,name=\"Act_C2_{}\".format(namebase))(conv_2)\n",
    "    newcriticlayers = AveragePooling2D(name=\"AvPool_C0_{}\".format(namebase))(act_2)\n",
    "    critic = newcriticlayers\n",
    "    # append the earlier model\n",
    "    for i in range(nSkip,len(old_c_model.layers)):\n",
    "        critic = old_c_model.layers[i](critic)\n",
    "    criticModel = Model(layer_in, critic)\n",
    "    \n",
    "    # define passby model, first downsample\n",
    "    pathtofade = AveragePooling2D(name=\"AvPool_CPass_{}\".format(namebase))(layer_in)\n",
    "    # note: including conv_0, and act_0 from previous layer\n",
    "    for i in range(nSkipPassby,nSkip):\n",
    "        pathtofade = old_c_model.layers[i](pathtofade)\n",
    "    critic_fade = AddWithFade(name=\"Fade_CPass_{}\".format(namebase))([pathtofade,newcriticlayers])\n",
    "    for i in range(nSkip,len(old_c_model.layers)):\n",
    "        critic_fade = old_c_model.layers[i](critic_fade)\n",
    "    criticFadeOut = Model(layer_in, critic_fade)\n",
    "    return [criticModel, criticFadeOut]\n",
    "\n",
    "# take from a model that generates an nxnx3 figure to one that generates a 2nx2nx3 figure\n",
    "def add_generator_level(old_g_model, new_level=8, nDrop=3,nDropPassby=1,nColors=3,nameX=None):\n",
    "    namebase = nameX\n",
    "    if nameX == None:\n",
    "        namebase = str(new_level)\n",
    "        \n",
    "    thisleveldict = leveldict[new_level]\n",
    "    filters = thisleveldict['filters']\n",
    "    \n",
    "    # get input\n",
    "    layer_in = old_g_model.input\n",
    "    # remove final layer\n",
    "    newendofold = old_g_model.layers[-2].output \n",
    "    sizeaugment = UpSampling2D(name=\"UpSample_G0_{}\".format(namebase))(newendofold)\n",
    "    \n",
    "    # first layer set\n",
    "    conv_1 = Conv2DELR(filters, (3,3), padding=\"SAME\",name=\"Conv_G1_{}\".format(namebase))(sizeaugment)\n",
    "    pixnorm_1 = PixelNorm(name=\"Pix_G1_{}\".format(namebase))(conv_1)\n",
    "    act_1 = LeakyReLU(alpha=0.2,name=\"Act_G1_{}\".format(namebase))(pixnorm_1)\n",
    "    # second layer set\n",
    "    conv_2 = Conv2DELR(filters, (3,3), padding=\"SAME\",name=\"Conv_G2_{}\".format(namebase))(act_1)\n",
    "    pixnorm_2 = PixelNorm(name=\"Pix_G2_{}\".format(namebase))(conv_2)\n",
    "    act_2 = LeakyReLU(alpha=0.2,name=\"Act_G2_{}\".format(namebase))(pixnorm_2)\n",
    "    \n",
    "    # save for combo below\n",
    "    conv_out = Conv2DELR(nColors, (1,1), padding=\"SAME\",name=\"Conv_Gout_{}\".format(namebase))(act_2)\n",
    "    genModel = Model(layer_in, conv_out)\n",
    "    \n",
    "    # define passby model\n",
    "    #old_end = old_g_model.layers[-1].output\n",
    "    #sizeaugment_fade = UpSampling2D(name=\"UpSample_GPass_{}\".format(namebase))(old_end)\n",
    "    old_end = old_g_model.layers[-1]\n",
    "    sizeaugment_fade = old_end(sizeaugment)\n",
    "    conv_out_fade = AddWithFade(name=\"Fade_GPass_{}\".format(namebase))([sizeaugment_fade,conv_out])\n",
    "    \n",
    "    genModelFade = Model(layer_in, conv_out_fade)\n",
    "    \n",
    "    return [genModel, genModelFade]\n",
    "\n",
    "# nLevels = number of pixelation levels (4,8,16,32,64,128) \n",
    "def create_critics(nColors=3, initialSize = 4, nLevels = 6):\n",
    "    # first create the lowest level critic\n",
    "    thisleveldict = leveldict[initialSize]\n",
    "    filters = thisleveldict['filters']\n",
    "    \n",
    "    #define new input layer\n",
    "    layer_in = Input(shape=(initialSize, initialSize, nColors,)) \n",
    "    # new round start passby here\n",
    "    # define new input processing layer\n",
    "    conv_0 = Conv2DELR(filters, (1,1), padding=\"SAME\")(layer_in)\n",
    "    act_0 = LeakyReLU(alpha=0.2)(conv_0)\n",
    "    # first layer set (newround start main model here)\n",
    "    # apply minibatch standard deviation\n",
    "    miniBDev = MBStDev()(act_0)\n",
    "    conv_1 = Conv2DELR(filters, (3,3), padding=\"SAME\")(miniBDev)\n",
    "    act_1 = LeakyReLU(alpha=0.2)(conv_1)\n",
    "    # second layer set (the end is a 4x4 convolution)\n",
    "    conv_2 = Conv2DELR(filters, (4,4), padding=\"SAME\")(act_1)\n",
    "    act_2 = LeakyReLU(alpha=0.2)(conv_2)\n",
    "    dense_out = Flatten()(act_2)\n",
    "    out_classifier = Dense(1)(dense_out)\n",
    "    \n",
    "    # define and compile model\n",
    "    initial_critic = Model(layer_in,out_classifier)\n",
    "    \n",
    "    # collect all models\n",
    "    modellist = [[initial_critic,initial_critic]]\n",
    "    curlevel = 4\n",
    "    for i in range(1,nLevels):\n",
    "        curlevel = curlevel * 2\n",
    "        # modellist[-1][0] corresponds to the version with no fade\n",
    "        newmodels = add_critic_level(modellist[-1][0], new_level=curlevel)\n",
    "        modellist.append(newmodels)\n",
    "    return modellist\n",
    "\n",
    "\n",
    "# nLevels = number of pixelation levels (4,8,16,32,64,128) \n",
    "def create_gens(nInputs = codings_size, nColors=3, initialSize = 4, nLevels = 6):\n",
    "    # first create the lowest level critic\n",
    "    thisleveldict = leveldict[initialSize]\n",
    "    filters = thisleveldict['filters']\n",
    "    # #4.1 weight initialization and maxnorm constraint\n",
    "    kinit = tf.keras.initializers.RandomNormal(stddev=1.)\n",
    "    \n",
    "    #define new input layer\n",
    "    layer_in = Input(shape=(nInputs,))\n",
    "    dense_0 = Dense(nInputs*initialSize*initialSize, kernel_initializer=kinit)(layer_in)\n",
    "    reshape_0 = Reshape((initialSize, initialSize, nInputs))(dense_0)\n",
    "    #may want to add activiation functions\n",
    "    # first layer set (start with 4x4)\n",
    "    conv_1 = Conv2DELR(filters, (4,4), padding=\"SAME\")(reshape_0)\n",
    "    pixnorm_1 = PixelNorm()(conv_1)\n",
    "    act_1 = LeakyReLU(alpha=0.2)(pixnorm_1)\n",
    "    # second layer set \n",
    "    conv_2 = Conv2DELR(filters, (3,3), padding=\"SAME\")(act_1)\n",
    "    pixnorm_2 = PixelNorm()(conv_2)\n",
    "    act_2 = LeakyReLU(alpha=0.2)(pixnorm_2)\n",
    "    # save for combo below\n",
    "    conv_out = Conv2DELR(nColors, (1,1), padding=\"SAME\")(act_2)\n",
    "    genModel = Model(layer_in, conv_out)\n",
    "    \n",
    "        \n",
    "    # collect all models\n",
    "    modellist = [[genModel,genModel]]\n",
    "    curlevel = 4\n",
    "    for i in range(1,nLevels):\n",
    "        curlevel = curlevel * 2\n",
    "        # modellist[-1][0] corresponds to the version with no fade\n",
    "        newmodels = add_generator_level(modellist[-1][0], new_level=curlevel)\n",
    "        modellist.append(newmodels)\n",
    "    return modellist\n",
    "\n",
    "def create_gans(gens,crits,nInputs = codings_size):\n",
    "    ganlist = []\n",
    "    assert len(gens)==len(crits), \"Generators and Discriminators created with different lengths\"\n",
    "    for i in range(len(gens)):\n",
    "        with strategy.scope():\n",
    "            # compile standard\n",
    "            wgan1 = WGANGP(discriminator=crits[i][0],generator=gens[i][0],latent_dim=nInputs,discriminator_steps=1)\n",
    "            wgan1.compile(d_optimizer=optimizercrit,g_optimizer=optimizergen,g_loss_fn=generator_loss,d_loss_fn=critic_loss)\n",
    "            # compile fade\n",
    "            wgan2 = WGANGP(discriminator=crits[i][1],generator=gens[i][1],latent_dim=nInputs,discriminator_steps=1)\n",
    "            wgan2.compile(d_optimizer=optimizercrit,g_optimizer=optimizergen,g_loss_fn=generator_loss,d_loss_fn=critic_loss)\n",
    "            # add to gan list\n",
    "            ganlist.append([wgan1,wgan2])\n",
    "    return ganlist\n",
    " \n",
    "########################\n",
    "### Image processing ###\n",
    "########################\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=25,\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=10,\n",
    "        zoom_range=[0.95,1.2],\n",
    "        brightness_range=[0.8,1.4],\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "# adjust the saturation of the image\n",
    "def colorSaturationAdjust(img, satRange=[0.6,1.4]):\n",
    "    rSat = random.triangular(satRange[0],satRange[1])\n",
    "    gSat = random.triangular(satRange[0],satRange[1])\n",
    "    bSat = random.triangular(satRange[0],satRange[1])\n",
    "    satVar = [rSat, gSat, bSat]\n",
    "    return np.clip(img * satVar,0,1)\n",
    "\n",
    "def multiprocessingI(imglist):\n",
    "    imglistproc = []\n",
    "    for img in datagen.flow((imglist+1.)/2.000)[0]:\n",
    "        imglistproc.append(np.clip(2.*(colorSaturationAdjust(img/255.0)-0.5),-1.,1.))\n",
    "        #imglistproc.append(colorSaturationAdjust(img/255.0))\n",
    "    return np.asarray(imglistproc)\n",
    "\n",
    "def multiprocessingI(imglist,new_length,batch_size):\n",
    "    imglistproc = []\n",
    "    for img in datagen.flow((imglist+1.)/2.000,batch_size=batch_size)[0]:\n",
    "        newimg = np.clip(2.*(colorSaturationAdjust(img/255.0)-0.5),-1.,1.)\n",
    "        imglistproc.append(cv2.resize(newimg, (new_length,new_length), interpolation = cv2.INTER_AREA))\n",
    "        #imglistproc.append(colorSaturationAdjust(img/255.0))\n",
    "    return np.asarray(imglistproc)\n",
    "\n",
    "\n",
    "##################################\n",
    "### Image display and file I/O ###\n",
    "##################################\n",
    "def plot_multiple_images(images, n_cols=None):\n",
    "    n_cols = n_cols or len(images)\n",
    "    n_rows = (len(images) - 1) // n_cols + 1\n",
    "    if images.shape[-1] == 1:\n",
    "        images = np.squeeze(images, axis=-1)\n",
    "    plt.figure(figsize=(n_cols, n_rows))\n",
    "    plt.subplots_adjust(hspace=0.03, wspace=0)\n",
    "    for index, image in enumerate(images):\n",
    "        plt.subplot(n_rows, n_cols, index + 1,snap=True)\n",
    "        plt.imshow(np.clip((image + 1.)/2.,0.,1.), cmap=\"binary\")\n",
    "        #plt.imshow(image, cmap=\"binary\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "def read_image(src):\n",
    "    img = cv2.imread(src)\n",
    "    if img is None:\n",
    "        print(src)\n",
    "        raise FileNotFoundError\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "def write_image(img,filename):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(filename, img)\n",
    "\n",
    "def constructGIF(ix,filename):\n",
    "    gif_path = GIFDIR+filename+\".gif\"\n",
    "    frames_path = GIFDIR+filename+\"_{i}.jpg\"\n",
    "    with imageio.get_writer(gif_path, mode='I') as writer:\n",
    "        for i in range(ix):\n",
    "            writer.append_data(imageio.imread(frames_path.format(i=i)))\n",
    "\n",
    "#IpyImage(filename=GIFDIR+modelname+\"_test.gif\")\n",
    "\n",
    "def plot_history(d_hist, g_hist):\n",
    "    plt.plot(d_hist, label='crit')\n",
    "    plt.plot(g_hist, label='gen')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.savefig(GIFDIR+'/plot_line_plot_loss.png')\n",
    "    plt.close()\n",
    "    \n",
    "def saveh5(model, name):\n",
    "    filename = h5DIR + name + '.h5'\n",
    "    model.save(filename)\n",
    "\n",
    "def saveh5s(model, name):\n",
    "    saveh5(model.generator, 'gen_'+ name)\n",
    "    saveh5(model.discriminator, 'crit_'+ name)\n",
    "\n",
    "def write_images_and_GIF(imgsetforGIF,modelname):\n",
    "    frames_path = GIFDIR+modelname+\"_{i}.jpg\"\n",
    "    for i, imgs in enumerate(imgsetforGIF):\n",
    "        plot_multiple_images(imgs, 8)\n",
    "        plt.savefig(frames_path.format(i=i))\n",
    "        plt.close()\n",
    "    constructGIF(len(imgsetforGIF),modelname)\n",
    "\n",
    "customOs={'LeakyReLU': LeakyReLU,'Conv2DELR': Conv2DELR,'PixelNorm':PixelNorm,\n",
    "          'AddWithFade':AddWithFade,'MBStDev':MBStDev}\n",
    "def loadh5s(name):\n",
    "    filename = h5inDIR + 'gen_' +name + '.h5'\n",
    "    generator = load_model(filename,custom_objects=customOs)\n",
    "    filename = h5inDIR + 'crit_' +name + '.h5'\n",
    "    critic = load_model(filename,custom_objects=customOs)\n",
    "    return generator, critic\n",
    "\n",
    "def load_hists(tag=\"\"):\n",
    "    with open(h5inDIR + 'g_loss_hist'+tag+'.dat', 'rb') as filehandle:\n",
    "        # read the data as binary data stream\n",
    "        g_loss_hist = pickle.load(filehandle)\n",
    "    with open(h5inDIR + 'd_loss_hist'+tag+'.dat', 'rb') as filehandle:\n",
    "        # read the data as binary data stream\n",
    "        d_loss_hist = pickle.load(filehandle)\n",
    "    return d_loss_hist, g_loss_hist\n",
    "\n",
    "def dump_hists(d_loss_hist, g_loss_hist):\n",
    "    with open(h5DIR + 'g_loss_hist.dat', 'wb') as filehandle:\n",
    "        # store the data as binary data stream\n",
    "        pickle.dump(g_loss_hist, filehandle)\n",
    "    with open(h5DIR + 'd_loss_hist.dat', 'wb') as filehandle:\n",
    "        # store the data as binary data stream\n",
    "        pickle.dump(d_loss_hist, filehandle)\n",
    "\n",
    "def dump_hists(d_loss_hist, g_loss_hist, tag=\"\"):\n",
    "    with open(h5DIR + 'g_loss_hist'+tag+'.dat', 'wb') as filehandle:\n",
    "        # store the data as binary data stream\n",
    "        pickle.dump(g_loss_hist, filehandle)\n",
    "    with open(h5DIR + 'd_loss_hist'+tag+'.dat', 'wb') as filehandle:\n",
    "        # store the data as binary data stream\n",
    "        pickle.dump(d_loss_hist, filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hSvRTHeebewS"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "#batch_size = 64\n",
    "modelname = 'WGANGPU64'\n",
    "\n",
    "tf.random.set_seed(7777)\n",
    "np.random.seed(7777)\n",
    "fixednoise = tf.random.normal(shape=[32, codings_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KLCflVt4lXiQ"
   },
   "outputs": [],
   "source": [
    "filelist = os.listdir(FishDIR)\n",
    "FishFiles = [ FishDIR+i for i in filelist if i[-3:]=='jpg' ]\n",
    "Xtrain = np.stack([ read_image(i) * np.float32(2. / 255.) - 1  for i in FishFiles ])\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(Xtrain)\n",
    "dataset = dataset.shuffle(1000)\n",
    "dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "psDTG7DmbfU5"
   },
   "outputs": [],
   "source": [
    "# do we fade and if so how much?\n",
    "setFade = False\n",
    "fadenImages = 1000000 #800k is NVIDIAs choice\n",
    "netEpochs = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KF8sA-XLN8yR"
   },
   "source": [
    "# Resize without ELR, shorter path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ggOQPSRmOEV9"
   },
   "outputs": [],
   "source": [
    "generator = Sequential([\n",
    "    Input(shape=(codings_size,)),\n",
    "    Dense(8 * 8 * 128),\n",
    "    Reshape([8, 8, 128]),\n",
    "    #Conv2DTranspose(256, (3,3), padding=\"SAME\"),\n",
    "    #PixelNorm(),\n",
    "    #LeakyReLU(alpha=0.2),\n",
    "    #Conv2DTranspose(256, (5,5), padding=\"SAME\"),\n",
    "    #PixelNorm(),\n",
    "    #LeakyReLU(alpha=0.2),\n",
    "    #UpSampling2D(),\n",
    "    # image 4x4 -> 8x8\n",
    "    Conv2DTranspose(128, (5,5), padding=\"SAME\"),\n",
    "    PixelNorm(),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    Conv2DTranspose(128, (4,4), padding=\"SAME\"),\n",
    "    PixelNorm(),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    UpSampling2D(),\n",
    "    # image 8x8 -> 16x16\n",
    "    #Conv2DTranspose(128, (3,3), padding=\"SAME\"),\n",
    "    #PixelNorm(),\n",
    "    #LeakyReLU(alpha=0.2),\n",
    "    Conv2DTranspose(128, (5,5), padding=\"SAME\"),\n",
    "    PixelNorm(),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    # image 16x16 -> 32x32\n",
    "    UpSampling2D(),\n",
    "    Conv2DTranspose(128, (5,5),  padding=\"SAME\"),\n",
    "    PixelNorm(),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    Conv2DTranspose(128, (5,5), padding=\"SAME\"),\n",
    "    PixelNorm(),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    # image 32x32 -> 64x64\n",
    "    UpSampling2D(),\n",
    "    Conv2DTranspose(128, (5,5),  padding=\"SAME\"),\n",
    "    PixelNorm(),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    #Conv2DTranspose(64, (5,5), strides=(2,2), padding=\"SAME\"),\n",
    "    #PixelNorm(),\n",
    "    #LeakyReLU(alpha=0.2),\n",
    "    # image 64x64 -> 128x128\n",
    "    #keras.layers.Conv2DTranspose(32, (5,5), strides=(2,2), padding=\"SAME\"),\n",
    "    #PixelNorm(),\n",
    "    #LeakyReLU(alpha=0.2),\n",
    "    Conv2DTranspose(3, (5,5), padding=\"SAME\",activation=\"tanh\")\n",
    "])\n",
    "discriminator = keras.models.Sequential([\n",
    "    Input(shape=(64, 64, 3,)),\n",
    "    Conv2D(128,  (5,5), padding=\"SAME\"),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    Dropout(dropoutVal),\n",
    "    # image 64x64 -> 32x32\n",
    "    Conv2D(128,  (4,4), strides=2, padding=\"SAME\"),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    Dropout(dropoutVal),\n",
    "    # image 32x32 -> 16x16 \n",
    "    Conv2D(128,  (4,4), strides=2, padding=\"SAME\"),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    Dropout(dropoutVal),\n",
    "    Conv2D(128,  (3,3), padding=\"SAME\"),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    Dropout(dropoutVal),\n",
    "    # image 16x16 -> 8x8\n",
    "    Conv2D(128,  (4,4), strides=2, padding=\"SAME\"),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    Dropout(dropoutVal),\n",
    "    # image 16x16 -> 4x4\n",
    "    Conv2D(256,  (4,4), strides=2, padding=\"SAME\"),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    Dropout(dropoutVal),\n",
    "    Conv2D(256,  (3,3), padding=\"SAME\"),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    Dropout(dropoutVal),\n",
    "    Conv2D(256,  (4,4), padding=\"SAME\"),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    MBStDev(),\n",
    "    Flatten(),\n",
    "    Dense(1) # note: use WGAN\n",
    "])\n",
    "\n",
    "optimizercrit=Adam(lr=0.001, beta_1=0, beta_2=0.99, epsilon=1e-8)\n",
    "optimizergen=Adam(lr=0.001, beta_1=0, beta_2=0.99, epsilon=1e-8)\n",
    "\n",
    "# compile first\n",
    "wgan = WGANGP(discriminator=discriminator,generator=generator,latent_dim=codings_size,discriminator_steps=1)\n",
    "wgan.compile(d_optimizer=optimizercrit,g_optimizer=optimizergen,g_loss_fn=generator_loss,d_loss_fn=critic_loss)\n",
    "\n",
    "modelname = 'WGANGPU64'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tExBoXXLxc04"
   },
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CvZx_OEyyAby"
   },
   "outputs": [],
   "source": [
    "# compile first\n",
    "wgan = WGANGP(discriminator=discriminator,generator=generator,latent_dim=codings_size,discriminator_steps=4)\n",
    "wgan.compile(d_optimizer=optimizercrit,g_optimizer=optimizergen,g_loss_fn=generator_loss,d_loss_fn=critic_loss)\n",
    "\n",
    "modelname = 'WGANGPU64'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KNGYQYY6YYKo"
   },
   "outputs": [],
   "source": [
    "d_loss_hist, g_loss_hist = list(), list()\n",
    "iCount=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1L-PkydGlh-A"
   },
   "outputs": [],
   "source": [
    "def train_wgan(wgan, dataset, batch_size, codings_size, image_size, n_epochs=10,iCount=0):\n",
    "    generator = wgan.generator\n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch + 1, n_epochs))  \n",
    "        d_loss, g_loss = 0, 0\n",
    "        starttime = time.time()\n",
    "        for X_batch in dataset:\n",
    "            with tf.device('/device:GPU:0'):\n",
    "                lossdict = wgan.train_step(multiprocessingI(X_batch,image_size,batch_size))\n",
    "            d_loss += lossdict['d_loss']\n",
    "            g_loss += lossdict['g_loss']\n",
    "        if epoch % 5 == 0 or epoch+1 == n_epochs: \n",
    "            generated_images = generator(fixednoise)\n",
    "            plot_multiple_images(generated_images, 8)\n",
    "            frames_path = GIFDIR+modelname+\"_{i}.png\"\n",
    "            plt.savefig(frames_path.format(i=iCount))\n",
    "            plt.show()    #note: show before save has the file blank\n",
    "            plt.close()\n",
    "            iCount+=1\n",
    "        #if epoch % 100 == 99:\n",
    "        #  saveh5s(wgan,savemodelname)\n",
    "        d_loss_hist.append(d_loss)\n",
    "        g_loss_hist.append(g_loss)\n",
    "        #if epoch % 10 == 0 and epoch > 20: \n",
    "        #    adapt_lr_GAN(wgan.g_optimizer, wgan.d_optimizer, g_loss_hist, d_loss_hist)\n",
    "        print('Epoch took {time:.3f} seconds: d_loss={dl:.3f},  g_loss={gl:.3f}'.format(time=time.time() - starttime, dl = d_loss, gl = g_loss)) \n",
    "        \n",
    "def update_2nd_gen(avmodel, newmodel, decayconst = 0.999):\n",
    "    weightlist = list()\n",
    "    aw = avmodel.get_weights()\n",
    "    nw = newmodel.get_weights()\n",
    "    for i in range(len(aw)):\n",
    "        weightlist.append(decayconst * aw[i] + (1.-decayconst)*nw[i])\n",
    "    avmodel.set_weights(weightlist)\n",
    "    \n",
    "def train_wgan_withav(wgan, dataset, batch_size, codings_size, image_size, avmodel=None, n_epochs=10,iCount=0,randd=False,randg=False):\n",
    "    generator = wgan.generator\n",
    "    if avmodel is None: \n",
    "        avmodel = keras.models.clone_model(wgan.generator)\n",
    "        avmodel.set_weights(wgan.generator.get_weights())\n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch + 1, n_epochs))  \n",
    "        d_loss, g_loss = 0, 0\n",
    "        starttime = time.time()\n",
    "        for X_batch in dataset:\n",
    "            lossdict = wgan.train_step(multiprocessingI(X_batch,image_size,batch_size),randd=randd,randg=randg)\n",
    "            d_loss += lossdict['d_loss']\n",
    "            g_loss += lossdict['g_loss']\n",
    "            # update moving average once per batch\n",
    "            update_2nd_gen(avmodel,wgan.generator)\n",
    "        if epoch % 5 == 0 or epoch+1 == n_epochs: \n",
    "            generated_images = generator(fixednoise)\n",
    "            plot_multiple_images(generated_images, 8)\n",
    "            #frames_path = GIFDIR+modelname+\"_{i}.png\"\n",
    "            #plt.savefig(frames_path.format(i=iCount))\n",
    "            plt.show()    #note: show before save has the file blank\n",
    "            plt.close()\n",
    "        if epoch % 10 == 9 or epoch+1 == n_epochs:\n",
    "            generated_images = avmodel(fixednoise)\n",
    "            plot_multiple_images(generated_images, 8)\n",
    "            frames_path = GIFDIR+modelname+\"_{i}.png\"\n",
    "            plt.savefig(frames_path.format(i=iCount))\n",
    "            plt.show()    #note: show before save has the file blank\n",
    "            plt.close()\n",
    "            iCount+=1\n",
    "        #if epoch % 100 == 99:\n",
    "        #  saveh5s(wgan,savemodelname)\n",
    "        d_loss_hist.append(d_loss)\n",
    "        g_loss_hist.append(g_loss)\n",
    "        print('Epoch took {time:.3f} seconds: d_loss={dl:.3f},  g_loss={gl:.3f}'.format(time=time.time() - starttime, dl = d_loss, gl = g_loss)) \n",
    "    return avmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7o7ycR95mP-w",
    "outputId": "e65d6e9a-7d67-44ee-bf1e-e3cadcc80929"
   },
   "outputs": [],
   "source": [
    "wgan.d_optimizer.lr = 0.0001\n",
    "wgan.g_optimizer.lr = 0.0001\n",
    "avgan = train_wgan_withav(wgan, dataset, batch_size, codings_size, 64, n_epochs=100,iCount=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "zQHqIXwNp5H6",
    "outputId": "5a707313-1f70-4140-e2bf-18d63078bb72"
   },
   "outputs": [],
   "source": [
    "wgan.d_optimizer.lr = 0.00005\n",
    "wgan.g_optimizer.lr = 0.00005\n",
    "avgan = train_wgan_withav(wgan, dataset, batch_size, codings_size, 64, n_epochs=300,iCount=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "wxgIInXmEmlZ",
    "outputId": "1f21a89a-baab-42a1-e07a-ea17a5cc994e"
   },
   "outputs": [],
   "source": [
    "wgan.d_optimizer.lr = 0.000025\n",
    "wgan.g_optimizer.lr = 0.000025\n",
    "avgan = train_wgan_withav(wgan, dataset, batch_size, codings_size, 64, avmodel=avgan, n_epochs=600,iCount=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "mgt1j1zb65cO",
    "outputId": "3c2106df-0c31-4e40-fa23-cd7856eedd65"
   },
   "outputs": [],
   "source": [
    "wgan = WGANGP(discriminator=discriminator,generator=generator,latent_dim=codings_size,discriminator_steps=4)\n",
    "wgan.compile(d_optimizer=optimizercrit,g_optimizer=optimizergen,g_loss_fn=generator_loss,d_loss_fn=critic_loss)\n",
    "avgan = train_wgan_withav(wgan, dataset, batch_size, codings_size, 64, avmodel=avgan, n_epochs=200,iCount=100,randg=True, randd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "colab_type": "code",
    "id": "n-k2dLkVpX5S",
    "outputId": "a8b0bdfa-7c22-4dce-d928-f267e343bdf6"
   },
   "outputs": [],
   "source": [
    "wgan.d_optimizer.lr = 0.00003\n",
    "wgan.g_optimizer.lr = 0.00003\n",
    "avgan = train_wgan_withav(wgan, dataset, batch_size, codings_size, 64, avmodel=avgan, n_epochs=200,iCount=120,randg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgan.d_optimizer.lr = 0.000025\n",
    "wgan.g_optimizer.lr = 0.000025\n",
    "avgan = train_wgan_withav(wgan, dataset, batch_size, codings_size, 64, avmodel=avgan, n_epochs=300,iCount=140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgan.d_optimizer.lr = 0.00002\n",
    "wgan.g_optimizer.lr = 0.00002\n",
    "avgan = train_wgan_withav(wgan, dataset, batch_size, codings_size, 64, avmodel=avgan, n_epochs=600,iCount=170)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pm5qiqoLLZb4"
   },
   "outputs": [],
   "source": [
    "modname=\"64_WGAN-GP\"\n",
    "saveh5s(wgan,modname)\n",
    "saveh5(avgan,'avgen'+modname)\n",
    "!tar -czf gif64WGAN.tar.gz GIFs\n",
    "dump_hists(d_loss_hist,g_loss_hist,modname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "JVQ5K9g-p72T",
    "outputId": "edf52841-e694-4ccb-b3de-3e7ced6559d6"
   },
   "outputs": [],
   "source": [
    "modname=\"64_WGAN-GP_a\"\n",
    "!tar -czf gif64_a.tar.gz GIFs\n",
    "dump_hists(d_loss_hist,g_loss_hist,modname)\n",
    "saveh5(wgan.generator,'gen_'+modname)\n",
    "saveh5(wgan.discriminator,'crit_'+modname)\n",
    "saveh5(avgan,'avgen'+modname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "br0mnwvWYKjm"
   },
   "source": [
    "\n",
    "\n",
    "# Generate from an existing h5 (version saved without fading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "TPIhS-jWp0d9",
    "outputId": "a1c2ce4c-ee38-401f-bab0-a9cdd6f8fec9"
   },
   "outputs": [],
   "source": [
    "loadmodelname = \"64_WGAN-GP_a\"\n",
    "generator, critic = loadh5s(loadmodelname)\n",
    "\n",
    "optimizercrit=Adam(lr=0.00003, beta_1=0, beta_2=0.99, epsilon=1e-8)\n",
    "optimizergen=Adam(lr=0.00003, beta_1=0, beta_2=0.99, epsilon=1e-8)\n",
    "\n",
    "wgan = WGANGP(discriminator=critic,generator=generator,latent_dim=codings_size,discriminator_steps=4)\n",
    "wgan.compile(d_optimizer=optimizercrit,g_optimizer=optimizergen,g_loss_fn=generator_loss,d_loss_fn=critic_loss)\n",
    "#generator.load_weights('gen_64_WGAN-GP_a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "shqN9oMmT17k"
   },
   "outputs": [],
   "source": [
    "wgan = WGANGP(discriminator=critic,generator=generator,latent_dim=codings_size,discriminator_steps=4)\n",
    "wgan.compile(d_optimizer=optimizercrit,g_optimizer=optimizergen,g_loss_fn=generator_loss,d_loss_fn=critic_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4a-N5WIY9heQ"
   },
   "outputs": [],
   "source": [
    "generated_images = wganFade.generator(fixednoise)\n",
    "plot_multiple_images(generated_images, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "V034VtQVpd2u",
    "outputId": "95e4fa81-4c6d-4c6d-bc44-7e40d1326eb7"
   },
   "outputs": [],
   "source": [
    "plot_history(d_loss_hist[25:], g_loss_hist[25:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadmodelname = \"64_WGAN-GP_b\"\n",
    "generator, critic = loadh5s(loadmodelname)\n",
    "\n",
    "optimizercrit=Adam(lr=0.00003, beta_1=0, beta_2=0.99, epsilon=1e-8)\n",
    "optimizergen=Adam(lr=0.00003, beta_1=0, beta_2=0.99, epsilon=1e-8)\n",
    "\n",
    "wgan = WGANGP(discriminator=critic,generator=generator,latent_dim=codings_size,discriminator_steps=4)\n",
    "wgan.compile(d_optimizer=optimizercrit,g_optimizer=optimizergen,g_loss_fn=generator_loss,d_loss_fn=critic_loss)\n",
    "#generator.load_weights('gen_64_WGAN-GP_a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(7777)\n",
    "np.random.seed(7777)\n",
    "fixednoise = tf.random.normal(shape=[32, codings_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ims = generator(fixednoise)\n",
    "plot_multiple_images(ims, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = tf.random.normal(shape=[100, codings_size])\n",
    "ims = generator(noise)\n",
    "plot_multiple_images(ims, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pA = noise[28]\n",
    "pB = noise[20]\n",
    "pC = noise[74]\n",
    "pD = noise[92]\n",
    "nstep = 9\n",
    "v1 = (pB-pA)/nstep\n",
    "v2 = (pC-pB)/nstep\n",
    "v3 = (pD-pC)/nstep\n",
    "v4 = (pA-pD)/nstep\n",
    "\n",
    "data = [pB + i * v2 for i in range(nstep+1)]\n",
    "data = data + [pC + i * v3 for i in range(nstep+1)]\n",
    "data = data + [pD + i * v4 for i in range(nstep+1)]\n",
    "data = data + [pA + i * v1 for i in range(nstep+1)]\n",
    "\n",
    "imx = generator(np.array(data))\n",
    "plot_multiple_images(imx, 10)\n",
    "\n",
    "plt.savefig(\"RoughTransition.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pA = noise[6]\n",
    "pB = noise[21]\n",
    "pC = noise[34]\n",
    "pD = noise[72]\n",
    "nstep = 9\n",
    "v1 = (pB-pA)/nstep\n",
    "v2 = (pC-pB)/nstep\n",
    "v3 = (pD-pC)/nstep\n",
    "v4 = (pA-pD)/nstep\n",
    "\n",
    "data = [pA + i * v1 for i in range(nstep+1)]\n",
    "data = data + [pB + i * v2 for i in range(nstep+1)]\n",
    "data = data + [pC + i * v3 for i in range(nstep+1)]\n",
    "data = data + [pD + i * v4 for i in range(nstep+1)]\n",
    "\n",
    "imx = generator(np.array(data))\n",
    "plot_multiple_images(imx, 10)\n",
    "\n",
    "plt.savefig(\"SmoothTransition.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# larger plot labels\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "Xr = list()\n",
    "for X in Xtrain:\n",
    "    Xr.append(cv2.resize(X, (64,64), interpolation = cv2.INTER_AREA))\n",
    "\n",
    "np.array(Xr).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lottanoise = tf.random.normal(shape=[256, codings_size])\n",
    "Xf = generator(lottanoise)\n",
    "for i in range(5):\n",
    "    lottanoise = tf.random.normal(shape=[256+2*i+6, codings_size])\n",
    "    Xf = tf.concat([Xf, generator(lottanoise)], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixel_dist(list1, list2, areSame=True):\n",
    "    distlist = list()\n",
    "    totalmin = 1000000\n",
    "    rClose = []\n",
    "    for X in list1:\n",
    "        mindist = 10000000000\n",
    "        for Y in list2:\n",
    "            if (X*1. == Y*1.).all() and areSame:\n",
    "                pass\n",
    "            else:\n",
    "                ceval = np.sqrt(np.sum((X-Y)**2))\n",
    "                if ceval < mindist:\n",
    "                    mindist = ceval\n",
    "                    if mindist < totalmin:\n",
    "                        rClose = [X,Y]\n",
    "                        totalmin = mindist\n",
    "        distlist.append(mindist)\n",
    "    return distlist, rClose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realdistlist, closest = get_pixel_dist(Xr,Xr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakedistlist, closestf = get_pixel_dist(np.array(Xf),np.array(Xf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossdistlist, closestc = get_pixel_dist(Xr,np.array(Xf),areSame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([realdistlist,fakedistlist,crossdistlist],label=[\"Real-Real\",\"Fake-Fake\",\"Real-Fake\"],density=True)\n",
    "plt.xlabel(\"Pixel distance\")\n",
    "plt.ylabel(\"Fraction per unit pixel\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig(\"pixelDistributions.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GIFDIR=\"./GIFs/\"\n",
    "def constructGIF(filename,ix):\n",
    "    gif_path = GIFDIR+filename+\".gif\"\n",
    "    frames_path = GIFDIR+filename+\"_{i}.png\"\n",
    "    with imageio.get_writer(gif_path, mode='I') as writer:\n",
    "        for i in range(ix):\n",
    "            writer.append_data(imageio.imread(frames_path.format(i=i)))\n",
    "constructGIF(\"WGANGPU64\",250)\n",
    "IpyImage(filename=GIFDIR+\"WGANGPU64\"+\".gif\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "4AbEGFzsYTcS",
    "0soVob9Fxw7R"
   ],
   "machine_shape": "hm",
   "name": "Copy of FishWGAN64.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
